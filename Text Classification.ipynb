{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1503,
     "status": "ok",
     "timestamp": 1665153344224,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "uctNgpSvv2w7"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1665153344224,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "cjK-wTgIyAaZ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/hys89/nlp-data-learningfri/main/horror&romance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1665153344225,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "Z0zYhea6yG00",
    "outputId": "c5414b0e-bd7b-449f-aae7-c3d0322ee4a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. 500 Word Limit. All stories must be 500 wor...</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was sitting on the soft snow with a blanket ...</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But the hatred that fills the room whenever he...</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I woke up hungry this morning. I've been sick ...</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had seen school shootings on television in t...</td>\n",
       "      <td>shortscarystories</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext          subreddit\n",
       "0  1. 500 Word Limit. All stories must be 500 wor...  shortscarystories\n",
       "1  I was sitting on the soft snow with a blanket ...  shortscarystories\n",
       "2  But the hatred that fills the room whenever he...  shortscarystories\n",
       "3  I woke up hungry this morning. I've been sick ...  shortscarystories\n",
       "4  I had seen school shootings on television in t...  shortscarystories"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-b2MaAPNyeE0"
   },
   "source": [
    "# Mapping Subreddit\n",
    "(shortscarystories -> 1, romance ->0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1665153344225,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "sBU1z5ZJyUvC",
    "outputId": "41e772d5-bd32-44b7-9da2-dc0b3d014a22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. 500 Word Limit. All stories must be 500 wor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was sitting on the soft snow with a blanket ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>But the hatred that fills the room whenever he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I woke up hungry this morning. I've been sick ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had seen school shootings on television in t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            selftext  subreddit\n",
       "0  1. 500 Word Limit. All stories must be 500 wor...          1\n",
       "1  I was sitting on the soft snow with a blanket ...          1\n",
       "2  But the hatred that fills the room whenever he...          1\n",
       "3  I woke up hungry this morning. I've been sick ...          1\n",
       "4  I had seen school shootings on television in t...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subreddit'] = df['subreddit'].map({'shortscarystories':1, 'romance':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w23Ba3NRyNRk"
   },
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665153344225,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "nYON2HStyJEZ"
   },
   "outputs": [],
   "source": [
    "X = df['selftext']\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1665153344226,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "pp93kXp8yRQt"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, stratify=y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1665153344226,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "EMbQ3W9HyR0B",
    "outputId": "c78ee668-1aa7-41eb-ae45-26c1aeaf8dda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    53.319058\n",
      "0    46.680942\n",
      "Name: subreddit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Checking strafication\n",
    "print (y_train.value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2-xDC-Uy6jg"
   },
   "source": [
    "# Training Process\n",
    "\n",
    "For purposes of demonstration, we will do the following:\n",
    "1. Implement basic text cleaning + tokenisation\n",
    "2. Lemmatising word tokens\n",
    "3. Build word count vectoriser as feature inputs into subsequent model\n",
    "4. Implement classification using logistic regression\n",
    "5. Evaluate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xz2PA8511Tsf"
   },
   "source": [
    "#### 1. Implement basic text cleaning + tokenisation\n",
    "#### 2. Lemmatising word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665153344226,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "4aJn20nzym3Q"
   },
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    words = re.sub(r\"[^A-Za-z0-9]\", \" \", str_input).lower().split() # Remove punctuation and tokenise\n",
    "    words = [WordNetLemmatizer().lemmatize(word) for word in words] # Lemmatise each word\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665153344227,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "XQezltTp0B0v"
   },
   "outputs": [],
   "source": [
    "# This is a set of stop words from sklearn\n",
    "stop_words = text.ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NiGmfk3K1dAx"
   },
   "source": [
    "#### 3. Build word count vectoriser as feature inputs into subsequent model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665153344227,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "Y7c9i25W0K4-"
   },
   "outputs": [],
   "source": [
    "# Create instance of vectoriser\n",
    "cvec = CountVectorizer(ngram_range=(1,2), stop_words=stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1665153345273,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "Zhi6qKiK0zZa"
   },
   "outputs": [],
   "source": [
    "X_train = cvec.fit_transform(X_train)\n",
    "X_test = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL_jnCIU1rfr"
   },
   "source": [
    "#### 4. Implement classification using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1665153345274,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "v5POfX3s1Nx1"
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2455,
     "status": "ok",
     "timestamp": 1665153347727,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "T5B1-hq910zE",
    "outputId": "d9360cd5-bfd0-4631-e24b-7934a1689bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AllyY6ZS2NBe"
   },
   "source": [
    "#### 5. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665153347727,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "_CMU-2Yh2EDH",
    "outputId": "56c1f13e-1d33-43eb-bada-8301a5b206b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9252136752136753"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy\n",
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665153347728,
     "user": {
      "displayName": "Solomon Heng",
      "userId": "17814351174437266977"
     },
     "user_tz": -480
    },
    "id": "o7427lX_2oFU",
    "outputId": "d3f89902-00fd-4391-cf4d-d49de092b872"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          Romance       0.90      0.95      0.92       219\n",
      "ShortScaryStories       0.95      0.90      0.93       249\n",
      "\n",
      "         accuracy                           0.93       468\n",
      "        macro avg       0.92      0.93      0.93       468\n",
      "     weighted avg       0.93      0.93      0.93       468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating test results\n",
    "print (classification_report(y_test, lr.predict(X_test), target_names=['Romance', 'ShortScaryStories']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPgUsysGbKO7Cs2nNgdGTGG",
   "collapsed_sections": [],
   "mount_file_id": "1McSOJH4jFuQDKtmyJYRGQNnioG9U7xb6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
